
## å‰è¨€
ä¸€ç›´éƒ½å¯¹ç›®æ ‡æ£€æµ‹å¾ˆæ„Ÿå…´è¶£ æ‰€ä»¥å°±è‡ªå·±ä»Žå¤´å¼€å§‹å®žçŽ°äº†ä¸€ä¸ªyolov3  è·¯é€”è¿˜æ˜¯æœ‰ç‚¹è‰°è¾›ðŸ˜€ðŸ˜„ å—çŽ¯å¢ƒç­‰å„æ–¹é¢å› ç´ ç›®å‰ä»…åœ¨ä¸€äº›ç®€å•çš„æ•°æ®ä¸Šè·‘å‡ºäº†ç»“æžœ

## ç‰¹æ€§
* é¡¹ç›®å®Œæ•´ æ•°æ®é¢„å¤„ç†å¤„ç†ã€anchorç”Ÿæˆã€é¢„è§ˆæ•°æ®ã€é¢„è§ˆè®­ç»ƒç»“æžœ
* ä½¿ç”¨æœ€æ–°ç‰ˆtensorflow2.2.0 æ¨¡åž‹éƒ¨åˆ†çº¯tensorflowå®žçŽ° åº”è¯¥æ˜¯å…¨ç¨‹äº«å—åŠ é€Ÿ
* æ¨¡å—åŒ–å®žçŽ° ç»“æž„ç®€æ´ å¯é˜…è¯»æ€§å¥½
* å®žæ—¶è®¡ç®—mAP
â€‹
## å…¶å®ƒ
* è§£ç ç”¨åŽŸè®ºæ–‡å…¬å¼è§£ç é•¿å®½å¾ˆå®¹æ˜“å‡ºçŽ°NaN æ‰€ä»¥æˆ‘å°†å…¶æ”¹ä¸ºäº†2 * sigmoid(p)
* åŠ¨æ€è®¡ç®—ç½®ä¿¡åº¦æ­£è´Ÿæ ·æœ¬æƒé‡

## è®­ç»ƒyymnist
å‡†å¤‡æ•°æ®
```shell script
git clone https://github.com/YunYang1994/yymnist.git
mkdir -p /tmp/yymnist/train
mkdir -p /tmp/yymnist/val
python yymnist/make_data.py --images_num 1000 --images_path ./data/dataset/train --labels_txt ./data/dataset/yymnist_train.txt
python yymnist/make_data.py --images_num 200  --images_path ./data/dataset/test  --labels_txt ./data/dataset/yymnist_test.txt
```

## è½¬æ¢label
tools -> convert_label_to_0_1.py

### ä¿®æ”¹
```python
LABEL_FILE = "/opt/datasets/yymnist_yolo/yymnist_train.txt"
OUTPUT_FILE = "/opt/datasets/yymnist_yolo/train_labels.txt"
```

## ä¿®æ”¹configä¸­æ•°æ®é…ç½®
```python
train_label_file = "/opt/datasets/yymnist_yolo/train_labels.txt"
train_image_dir = "/opt/datasets/yymnist_yolo/train"
val_label_file = "/opt/datasets/yymnist_yolo/val_labels.txt"
val_image_dir = "/opt/datasets/yymnist_yolo/test"
```

## ç”Ÿæˆanchors(èšç±»å¯èƒ½ä¼šå‡ºçŽ°æŸä¸ªç±»ä¸ºç©ºçš„æƒ…å†µ ç»“æžœå°±ä¼šä¸ºç©º è‡ªå·±æ‰‹åŠ¨å°†å…¶æ”¹ä¸ºåˆé€‚çš„å€¼å°±å¥½)
tools -> get_anchors.py

## å°†ç”Ÿæˆçš„anchorsé…ç½®çš„é…ç½®æ–‡ä»¶
```python
anchor_sizes = [[[14.000000000000002, 14.000000000000002], [22.000000000000007, 22.0], [28.0, 28.0]],
                [[42.0, 42.0], [56.00000000000001, 56.00000000000001], [84.00000000000001, 84.00000000000001]],
                [[111.99999999999997, 111.99999999999997], [200, 200], [250, 250]]]
```
## é¢„è§ˆè®­ç»ƒæ•°æ®(ç»¿è‰²è¡¨ç¤ºçœŸå®žæ¡† çº¢è‰²è¡¨ç¤ºå¯¹åº”çš„anchor)
tools -> dataset_previews
<p align="center">
    <img src="https://github.com/open-cmdb/yolov3/blob/master/images/yolov3-datasets-preview.png">
</p>

## è®­ç»ƒ
train.py

```text
Epoch 00051: val_output_4_map did not improve from 0.79128
250/250 [==============================] - 138s 551ms/step - loss: 3.1002 - output_1_loss: 0.0591 - output_2_loss: 0.0308 - output_3_loss: 0.0059 - output_4_loss: 0.0000e+00 - output_1_location_1: 1.0000 - output_2_confidence_1: 0.9970 - output_2_true_confidence_1: 1.0000 - output_2_false_confidence_1: 0.9970 - output_3_categorical_1: 1.0000 - output_4_precision_1: 0.1617 - output_4_recall_1: 1.0000 - output_4_map: 0.9049 - val_loss: 3.4197 - val_output_1_loss: 0.0861 - val_output_2_loss: 0.0559 - val_output_3_loss: 0.2740 - val_output_4_loss: 0.0000e+00 - val_output_1_location_1: 1.0000 - val_output_2_confidence_1: 0.9972 - val_output_2_true_confidence_1: 0.9941 - val_output_2_false_confidence_1: 0.9972 - val_output_3_categorical_1: 0.9135 - val_output_4_precision_1: 0.1514 - val_output_4_recall_1: 0.9110 - val_output_4_map: 0.7884

ap:
 [0.7132132053375244,
 0.9144498109817505,
 0.8080149292945862,
 0.7785018086433411,
 0.8017507195472717,
 0.8155587315559387,
 0.8004550933837891,
 0.7287811040878296,
 0.7686083912849426,
 0.7549148201942444]

recall:
 [0.8333333134651184,
 0.9622641801834106,
 0.9189189076423645,
 0.8549618124961853,
 0.8991596698760986,
 0.9207921028137207,
 0.9351851940155029,
 0.8606557250022888,
 0.8333333134651184,
 0.8571428656578064]

precision:
 [0.8558558821678162,
 0.9503105878829956,
 0.8793103694915771,
 0.9105691313743591,
 0.8916666507720947,
 0.8857142925262451,
 0.8559321761131287,
 0.8467742204666138,
 0.9223300814628601,
 0.8807339668273926]
```

<p align="center">
    <img src="https://github.com/open-cmdb/yolov3/blob/master/images/yolov3-tensorboard.png">
</p>



## æŒ‡æ ‡è¯´æ˜Ž
* output_1_loss: åæ ‡æŸå¤±(GIOU)
* output_2_loss: ç½®ä¿¡åº¦æŸå¤±(Binary cross entropy)
* output_3_loss: åˆ†ç±»æŸå¤±(categorical cross entropy)
* output_4_loss: ä¸ºäº†å’Œæ•°æ®è¾“å‡ºä¿æŒä¸€è‡´ æ²¡æœ‰ä»»ä½•æ„ä¹‰

* output_1_location_1:        åæ ‡å‡†ç¡®çŽ‡
* output_2_confidence_1:      æ€»çš„ç½®ä¿¡åº¦å‡†ç¡®çŽ‡
* output_2_true_confidence_1: æ­£æ ·æœ¬ç½®ä¿¡åº¦å‡†ç¡®çŽ‡
* output_2_false_confidence_1:è´Ÿæ ·æœ¬ç½®ä¿¡åº¦å‡†ç¡®çŽ‡
* output_3_categorical_1:     åˆ†ç±»å‡†ç¡®çŽ‡
* output_4_precision_1:       ç²¾å‡†çŽ‡ï¼ˆä¸è€ƒè™‘ç±»åˆ«ï¼‰
* output_4_recall_1:          å¬å›žçŽ‡ï¼ˆä¸è€ƒè™‘ç±»åˆ«ï¼‰
* output_4_map:               mAP


## é¢„æµ‹
tools -> predict_test_images.py